{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pnstyler.styler as styler\n",
    "from data_preprocess import trajectory_to_ase_atoms, preprocess_asedb\n",
    "from train import get_dataset\n",
    "import ml_confs\n",
    "from tqdm.auto import tqdm\n",
    "from kooplearn.nn.functional import vamp_score, relaxed_projection_score\n",
    "\n",
    "from pathlib import Path\n",
    "import schnetpack\n",
    "import logging \n",
    "from input_pipeline import TimeLaggedSampler\n",
    "from model import GraphDPNet\n",
    "import torch\n",
    "import lightning\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Key              </span>┃<span style=\"font-weight: bold\"> Value                                                                        </span>┃<span style=\"font-weight: bold\"> Type  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│ topology_path    │ /media/data/pnovelli/md_datasets/chignolin-unbiased/CLN025-0-protein.pdb     │ str   │\n",
       "│ trajectory_path  │ /media/data/pnovelli/md_datasets/chignolin-unbiased/CLN025-0-protein-ALL.dcd │ str   │\n",
       "│ selection        │ backbone                                                                     │ str   │\n",
       "│ data_path        │ /home/pnovelli/code/dp_examples/chignolin/schnetpack/data                    │ str   │\n",
       "│ n_final_features │ 16                                                                           │ int   │\n",
       "│ n_atom_basis     │ 64                                                                           │ int   │\n",
       "│ n_interactions   │ 3                                                                            │ int   │\n",
       "│ n_rbf            │ 20                                                                           │ int   │\n",
       "│ cutoff           │ 10.0                                                                         │ float │\n",
       "│ batch_size       │ 392                                                                          │ int   │\n",
       "│ lagtime          │ 1                                                                            │ int   │\n",
       "│ max_epochs       │ 100                                                                          │ int   │\n",
       "│ use_relaxed_loss │ True                                                                         │ bool  │\n",
       "│ metric_loss      │ 0.01                                                                         │ float │\n",
       "│ seed             │ 0                                                                            │ int   │\n",
       "└──────────────────┴──────────────────────────────────────────────────────────────────────────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mKey             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                                                                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mType \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│ topology_path    │ /media/data/pnovelli/md_datasets/chignolin-unbiased/CLN025-0-protein.pdb     │ str   │\n",
       "│ trajectory_path  │ /media/data/pnovelli/md_datasets/chignolin-unbiased/CLN025-0-protein-ALL.dcd │ str   │\n",
       "│ selection        │ backbone                                                                     │ str   │\n",
       "│ data_path        │ /home/pnovelli/code/dp_examples/chignolin/schnetpack/data                    │ str   │\n",
       "│ n_final_features │ 16                                                                           │ int   │\n",
       "│ n_atom_basis     │ 64                                                                           │ int   │\n",
       "│ n_interactions   │ 3                                                                            │ int   │\n",
       "│ n_rbf            │ 20                                                                           │ int   │\n",
       "│ cutoff           │ 10.0                                                                         │ float │\n",
       "│ batch_size       │ 392                                                                          │ int   │\n",
       "│ lagtime          │ 1                                                                            │ int   │\n",
       "│ max_epochs       │ 100                                                                          │ int   │\n",
       "│ use_relaxed_loss │ True                                                                         │ bool  │\n",
       "│ metric_loss      │ 0.01                                                                         │ float │\n",
       "│ seed             │ 0                                                                            │ int   │\n",
       "└──────────────────┴──────────────────────────────────────────────────────────────────────────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "configs = ml_confs.from_file('configs.yaml')\n",
    "configs.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trajectory_to_ase_atoms(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess_asedb(cutoff, '/home/pnovelli/code/dp_examples/chignolin/schnetpack/data/CLN025-0-protein_backbone.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = Path('/home/pnovelli/code/dp_examples/chignolin/schnetpack/data/CLN025-0-protein_backbone.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(db_path, configs.cutoff)\n",
    "n_atoms = dataset[0][schnetpack.properties.n_atoms].item()\n",
    "\n",
    "model = GraphDPNet(\n",
    "        configs,\n",
    "        n_atoms,\n",
    "        torch.optim.Adam,\n",
    "        use_relaxed_loss=configs.use_relaxed_loss,\n",
    "        metric_deformation_loss_coefficient=configs.metric_loss,\n",
    "        optimizer_kwargs={\"lr\": 1e-2},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2048 [00:10<1:56:10,  3.41s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/pnovelli/code/dp_examples/chignolin/schnetpack/dev.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Buge1/home/pnovelli/code/dp_examples/chignolin/schnetpack/dev.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m2048\u001b[39m)):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Buge1/home/pnovelli/code/dp_examples/chignolin/schnetpack/dev.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m         data \u001b[39m=\u001b[39m dataset[i]\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Buge1/home/pnovelli/code/dp_examples/chignolin/schnetpack/dev.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m         out \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Buge1/home/pnovelli/code/dp_examples/chignolin/schnetpack/dev.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m         fmap\u001b[39m.\u001b[39mappend(out[\u001b[39m'\u001b[39m\u001b[39mscalar_representation\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msqueeze())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Buge1/home/pnovelli/code/dp_examples/chignolin/schnetpack/dev.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m fmap \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(fmap)\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/dp_examples/chignolin/schnetpack/model.py:45\u001b[0m, in \u001b[0;36mGraphDPNet.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mschnet(inputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/dp_examples/chignolin/schnetpack/model.py:109\u001b[0m, in \u001b[0;36mSchNet.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    108\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpwise_dist(inputs)\n\u001b[0;32m--> 109\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet(inputs)\n\u001b[1;32m    110\u001b[0m     inputs[\u001b[39m\"\u001b[39m\u001b[39mscalar_representation\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_lin(\n\u001b[1;32m    111\u001b[0m         inputs[\u001b[39m\"\u001b[39m\u001b[39mscalar_representation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m     \u001b[39mreturn\u001b[39;00m inputs\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/schnetpack/representation/schnet.py:152\u001b[0m, in \u001b[0;36mSchNet.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39m# compute interaction block to update atomic embeddings\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39mfor\u001b[39;00m interaction \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minteractions:\n\u001b[0;32m--> 152\u001b[0m     v \u001b[39m=\u001b[39m interaction(x, f_ij, idx_i, idx_j, rcut_ij)\n\u001b[1;32m    153\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m v\n\u001b[1;32m    155\u001b[0m inputs[\u001b[39m\"\u001b[39m\u001b[39mscalar_representation\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m x\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/schnetpack/representation/schnet.py:62\u001b[0m, in \u001b[0;36mSchNetInteraction.forward\u001b[0;34m(self, x, f_ij, idx_i, idx_j, rcut_ij)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute interaction output.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39m    atom features after interaction\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min2f(x)\n\u001b[0;32m---> 62\u001b[0m Wij \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilter_network(f_ij)\n\u001b[1;32m     63\u001b[0m Wij \u001b[39m=\u001b[39m Wij \u001b[39m*\u001b[39m rcut_ij[:, \u001b[39mNone\u001b[39;00m]\n\u001b[1;32m     65\u001b[0m \u001b[39m# continuous-filter convolution\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'ckpt/daily-rain-10/epoch=99-step=16700.ckpt'\n",
    "model = GraphDPNet.load_from_checkpoint(checkpoint_path, configs=configs, optimizer = torch.optim.Adam)\n",
    "model.to('cpu')\n",
    "fmap = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(2048)):\n",
    "        data = dataset[i]\n",
    "        out = model(data)\n",
    "        fmap.append(out['scalar_representation'].squeeze())\n",
    "fmap = torch.tensor(fmap)\n",
    "fmap = fmap.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fmap[:-1]\n",
    "Y = fmap[1:]\n",
    "\n",
    "_norm = torch.rsqrt(torch.tensor(encoded_X.shape[0]))\n",
    "encoded_X *= _norm\n",
    "encoded_Y *= _norm\n",
    "\n",
    "cov_X = torch.mm(encoded_X.T, encoded_X)\n",
    "cov_Y = torch.mm(encoded_Y.T, encoded_Y)\n",
    "cov_XY = torch.mm(encoded_X.T, encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, vecs = np.linalg.eigh(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.52772163e-04, 2.36804724e-04, 5.87446966e-04, 1.35341729e-03,\n",
       "       4.85378354e-03, 6.21326797e-03, 2.49874705e-02, 5.19040921e-02,\n",
       "       8.22884161e-02, 1.45571794e-01, 3.09330047e-01, 4.76245486e-01,\n",
       "       2.39180486e+00, 5.12561120e+00, 2.58280021e+01, 1.01491094e+02])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpietronvll\u001b[0m (\u001b[33mcsml\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20231116_155231-id9m2cyw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/csml/GraphDPNet-chignolin/runs/id9m2cyw' target=\"_blank\">gallant-river-1</a></strong> to <a href='https://wandb.ai/csml/GraphDPNet-chignolin' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/csml/GraphDPNet-chignolin' target=\"_blank\">https://wandb.ai/csml/GraphDPNet-chignolin</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/csml/GraphDPNet-chignolin/runs/id9m2cyw' target=\"_blank\">https://wandb.ai/csml/GraphDPNet-chignolin/runs/id9m2cyw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_logger = lightning.pytorch.loggers.WandbLogger(project='GraphDPNet-chignolin', entity='csml')\n",
    "\n",
    "lr_finder_cb = lightning.pytorch.callbacks.LearningRateFinder()\n",
    "\n",
    "ckpt_path = db_path.parent.parent / 'ckpt' / str(train_logger.experiment.name)\n",
    "ckpt_cb = lightning.pytorch.callbacks.ModelCheckpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = lightning.Trainer(\n",
    "    accelerator='gpu', \n",
    "    #logger=train_logger, \n",
    "    max_epochs=2, \n",
    "    callbacks=[lr_finder_cb, ckpt_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pnovelli/miniforge3/envs/schnetpack/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:43: attribute 'configs' removed from hparams because it cannot be pickled\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GraphDPNet' object has no attribute '_optimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/pnovelli/code/dp_examples/chignolin/schnetpack/dev.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Buge1/home/pnovelli/code/dp_examples/chignolin/schnetpack/dev.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, dataloader)\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    545\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    546\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    582\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:965\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger_connector\u001b[39m.\u001b[39mreset_metrics()\n\u001b[1;32m    964\u001b[0m \u001b[39m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[0;32m--> 965\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49msetup(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    967\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39m==\u001b[39m TrainerFn\u001b[39m.\u001b[39mFITTING:\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/lightning/pytorch/strategies/single_device.py:78\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup\u001b[39m(\u001b[39mself\u001b[39m, trainer: pl\u001b[39m.\u001b[39mTrainer) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_to_device()\n\u001b[0;32m---> 78\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msetup(trainer)\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:151\u001b[0m, in \u001b[0;36mStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39msetup(trainer)\n\u001b[0;32m--> 151\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup_optimizers(trainer)\n\u001b[1;32m    152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msetup_precision_plugin()\n\u001b[1;32m    153\u001b[0m _optimizers_to_device(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:140\u001b[0m, in \u001b[0;36mStrategy.setup_optimizers\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_scheduler_configs \u001b[39m=\u001b[39m _init_optimizers_and_lr_schedulers(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module)\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py:177\u001b[0m, in \u001b[0;36m_init_optimizers_and_lr_schedulers\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls `LightningModule.configure_optimizers` and parses and validates the output.\"\"\"\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpytorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrainer\u001b[39;00m \u001b[39mimport\u001b[39;00m call\n\u001b[0;32m--> 177\u001b[0m optim_conf \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_lightning_module_hook(model\u001b[39m.\u001b[39;49mtrainer, \u001b[39m\"\u001b[39;49m\u001b[39mconfigure_optimizers\u001b[39;49m\u001b[39m\"\u001b[39;49m, pl_module\u001b[39m=\u001b[39;49mmodel)\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m optim_conf \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     rank_zero_warn(\n\u001b[1;32m    181\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    182\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:157\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[1;32m    156\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 157\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    159\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    160\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/code/dp_examples/chignolin/schnetpack/model.py:86\u001b[0m, in \u001b[0;36mGraphDPNet.configure_optimizers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfigure_optimizers\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     85\u001b[0m     kw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt_kwargs \u001b[39m|\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr}\n\u001b[0;32m---> 86\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters(), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[0;32m~/miniforge3/envs/schnetpack/lib/python3.11/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GraphDPNet' object has no attribute '_optimizer'"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loading\n",
    "dataset = get_dataset(db_path, cutoff)\n",
    "batch_sampler = TimeLaggedSampler(dataset, batch_size = configs.training.batch_size, lagtime = configs.data.lagtime, shuffle = configs.training.shuffle)\n",
    "dataloader = schnetpack.data.AtomsLoader(dataset, batch_sampler=batch_sampler, num_workers=20, persistent_workers=True)\n",
    "\n",
    "\n",
    "#Optimizer\n",
    "optimizer = torch.optim.Adam\n",
    "#Model\n",
    "n_atoms = dataset[0][schnetpack.properties.n_atoms].item()\n",
    "model = GraphDPNet(configs, n_atoms, optimizer, use_relaxed_loss = True, metric_deformation_loss_coefficient=1.0,  optimizer_kargs= {'lr': 1e-3})\n",
    "logger = lightning.loggers.WandbLogger(project=configs.wandb.project_name, config=configs.to_dict(), entity=configs.wandb.entity)\n",
    "\n",
    "\n",
    "\n",
    "ckpt_path = os.path.join(ckpt_path, str(logger.experiment.name))\n",
    "ckpt_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val/P',\n",
    "    dirpath = ckpt_path,\n",
    "    mode = 'max', \n",
    "    save_top_k = 5, \n",
    "    save_last = True\n",
    ")\n",
    "\n",
    "trainer = lightning.Trainer(\n",
    "    accelerator='gpu', \n",
    "    logger=logger, \n",
    "    max_epochs=configs.training.epochs, \n",
    "    log_every_n_steps=configs.training.log_every,\n",
    "    callbacks=[ckpt_callback],\n",
    "    limit_val_batches = 10,\n",
    "    val_check_interval = configs.training.log_every\n",
    "    )\n",
    "trainer.fit(model, dataloader, val_dataloaders=dataloader) #Using the same data for tranining and validation is not kosher, but it's a hack for now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schnetpack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
